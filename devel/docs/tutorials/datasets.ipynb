{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IPython Notebook](datasets.ipynb) |  [Python Script](datasets.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "============================\n",
    "\n",
    "Datasets tell PHOEBE how and at what times to compute the model.  In some cases these will include the actual observational data, and in other cases may only include the times at which you want to compute a synthetic model.\n",
    "\n",
    "Adding a dataset - even if it doesn't contain any observational data - is required in order to compute a synthetic model (which will be described in the following [Compute Tutorial](compute).\n",
    "\n",
    "Setup\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As always, let's do imports and initialize a logger and a new Bundle.  See [Building a System](building_a_system.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Constant u'Gravitational constant' is already has a definition in the u'si' system [astropy.constants.constant]\n",
      "WARNING:astropy:Constant u'Gravitational constant' is already has a definition in the u'si' system\n",
      "WARNING: Constant u'Solar mass' is already has a definition in the u'si' system [astropy.constants.constant]\n",
      "WARNING:astropy:Constant u'Solar mass' is already has a definition in the u'si' system\n",
      "WARNING: Constant u'Solar radius' is already has a definition in the u'si' system [astropy.constants.constant]\n",
      "WARNING:astropy:Constant u'Solar radius' is already has a definition in the u'si' system\n",
      "WARNING: Constant u'Solar luminosity' is already has a definition in the u'si' system [astropy.constants.constant]\n",
      "WARNING:astropy:Constant u'Solar luminosity' is already has a definition in the u'si' system\n",
      "/usr/local/lib/python2.7/dist-packages/astropy/units/quantity.py:732: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  return super(Quantity, self).__eq__(other)\n"
     ]
    }
   ],
   "source": [
    "import phoebe2\n",
    "from phoebe2 import u # units\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = phoebe2.logger(clevel='INFO')\n",
    "\n",
    "b = phoebe2.Bundle.default_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a Dataset from Arrays\n",
    "--------------------------------------\n",
    "\n",
    "To add a dataset, you need to provide the function in\n",
    "phoebe2.parameters.dataset for the particular type of data you're dealing with, as well\n",
    "as any of your \"observed\" arrays.\n",
    "\n",
    "The available methods include:\n",
    "\n",
    "* ORB (orbit/positional data)\n",
    "* MESH (discretized mesh of stars)\n",
    "* LC (light curve)\n",
    "* RV (radial velocity)\n",
    "* ETV (eclipse timing variations)\n",
    "* more coming soon\n",
    "\n",
    "### Without Observations\n",
    "\n",
    "The simplest case of adding a dataset is when you do not have observational \"data\" and only want to compute a synthetic model.  Here all you need to provide is an array of times and information about the type of data and how to compute it.\n",
    "\n",
    "This situation will almost always be the case for orbits and meshes - its unlikely that you have observed positions and velocities for each of your components, but you still may like to store that information for plotting or diagnostic purposes.\n",
    "\n",
    "Here we'll do just that - we'll add an orbit dataset which will track the positions and velocities of both our 'primary' and 'secondary' stars (by their component tags) at each of the provided times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 3 parameters | components: _default, primary, secondary>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset(phoebe2.dataset.orb, time=np.linspace(0,10,20), dataset='orb01', component=['primary', 'secondary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you could probably predict by now, add_dataset can either take a function or the name of a function in phoebe2.parameters.dataset.  The following line would do the same thing (except we'll give it a new dataset tag to avoid throwing an error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 3 parameters | components: _default, primary, secondary>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('ORB', time=np.linspace(0,10,20), dataset='orb02', component=['primary', 'secondary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that dataset methods are referred to in uppercase.  Providing 'orb' here instead of 'ORB' will work, but in all cases we'll use the official uppercase designation.\n",
    "\n",
    "You may notice that add_dataset does take some time to complete.  In the background, the passband is being loaded (when applicable) and many parameters are created and attached to the Bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not provide a list of component(s), they will be assumed for you based on the dataset method.  Light curves and meshes can only attach at the system level (component=None), for instance, whereas RVs and ETVs can attach for each star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 24 parameters | methods: RV, RV_dep>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('RV', time=np.linspace(0,10,20), dataset='rv01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_default', 'primary', 'secondary']\n"
     ]
    }
   ],
   "source": [
    "print b.filter(dataset='rv01').components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll add an RV dataset and see that it was automatically created for both stars in our system, as well as for '\\_default'.  The default parameters hold the values that will be replicated if a new component is added to the system in the future.\n",
    "\n",
    "Since we did not explicitly state that we only wanted the primary and secondary components, the time array on '\\_default' is filled as well.  If we were then to add a tertiary component, its RVs would automatically be computed because of this replicated time array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualifier: time\n",
      "Description: Observed times\n",
      "Value: [  0.           0.52631579   1.05263158 ...,   8.94736842\n",
      "   9.47368421  10.        ] d\n",
      "Constrained by: \n",
      "Constrains: None\n",
      "Related to: None\n"
     ]
    }
   ],
   "source": [
    "print b['time@_default@rv01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'ORB' datasets defined earlier, on the other hand, we explicitly provided components.  In that case the '\\_default' times will be empty - adding a new component will result in this empty array being replicated and the orbit will NOT be computed for the tertiary component.  Of course, you could always manually copy the time array at a later time if you wanted the orbit to be computed.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualifier: time\n",
      "Description: Observed times\n",
      "Value: [] d\n",
      "Constrained by: \n",
      "Constrains: None\n",
      "Related to: None\n"
     ]
    }
   ],
   "source": [
    "print b['time@_default@orb01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on self-replicating parameters, see the \"copy for\" section in the [General Concepts Tutorial](general_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Observations\n",
    "\n",
    "Loading datasets with observations is (nearly) as simple.  \n",
    "\n",
    "Passing arrays to any of the dataset columns will apply it to all of the same components in which the time will be applied (see the 'Without Observations' section above for more details).  This make perfect sense for fluxes in light curves where the time and flux arrays are both at the system level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | methods: LC, LC_dep>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('LC', time=[0,1], flux=[1,0.5], dataset='lc01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualifier: flux\n",
      "Description: Observed flux\n",
      "Value: [ 1.   0.5] W / m3\n",
      "Constrained by: \n",
      "Constrains: None\n",
      "Related to: None\n"
     ]
    }
   ],
   "source": [
    "print b['flux@lc01@dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For datasets which attach to individual components, however, this isn't always the desired behavior.\n",
    "\n",
    "For a single-lined RV where we only attach to one component, everything is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 24 parameters | methods: RV, RV_dep>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('RV', time=[0,1], rv=[-3,3], dataset='rv02', component='primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv@_default@rv02@dataset: [] km / s\n",
      "rv@primary@rv02@dataset: [-3.  3.] km / s\n",
      "rv@secondary@rv02@dataset: [] km / s\n"
     ]
    }
   ],
   "source": [
    "print b['rv@rv02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for a double-lined RV we probably **don't** want to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 24 parameters | methods: RV, RV_dep>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('RV', time=[0,1], rv=[-3,3], dataset='rv03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv@_default@rv03@dataset: [-3.  3.] km / s\n",
      "rv@primary@rv03@dataset: [-3.  3.] km / s\n",
      "rv@secondary@rv03@dataset: [-3.  3.] km / s\n"
     ]
    }
   ],
   "source": [
    "print b['rv@rv03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we want to pass different arrays to the 'rv@primary' and 'rv@secondary'.  This can be done by explicitly stating the components in a dictionary sent to that argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 24 parameters | methods: RV, RV_dep>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('RV', time=[0,1], rv={'primary': [-3,3], 'secondary': [4,-4]}, dataset='rv04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv@_default@rv04@dataset: [] km / s\n",
      "rv@primary@rv04@dataset: [-3.  3.] km / s\n",
      "rv@secondary@rv04@dataset: [ 4. -4.] km / s\n"
     ]
    }
   ],
   "source": [
    "print b['rv@rv04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could of course not pass the values while calling add_dataset and instead call the set_value method after and explicitly state the components at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Passband Options\n",
    "\n",
    "Passband options follow the exact same rules as dataset columns.\n",
    "\n",
    "Sending a single value to the argument will apply it to *each* component in which the time array is attached (either based on the list of components sent or the defaults from the dataset method).\n",
    "\n",
    "Note that for light curves, in particular, this rule gets slightly bent.  The dataset arrays for light curves are attached at the system level, *always*.  The passband-dependent options, however, exist for each star in the system.  So, that value will get passed to each star if the component is not explicitly provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | methods: LC, LC_dep>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('LC', time=[0,1], ld_coeffs=[0,0], dataset='lc02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualifier: time\n",
      "Description: Observed times\n",
      "Value: [ 0.  1.] d\n",
      "Constrained by: \n",
      "Constrains: None\n",
      "Related to: None\n"
     ]
    }
   ],
   "source": [
    "print b['time@lc02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_coeffs@_default@lc02@dataset: [ 0.  0.]\n",
      "ld_coeffs@primary@lc02@dataset: [ 0.  0.]\n",
      "ld_coeffs@secondary@lc02@dataset: [ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print b['ld_coeffs@lc02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, if you want to pass different values to different components, simply provide them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | methods: LC, LC_dep>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('LC', time=[0,1], ld_coeffs={'primary': [0,0], 'secondary': [0.25, 0.25]}, dataset='lc03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_coeffs@_default@lc03@dataset: [ 0.5  0.5]\n",
      "ld_coeffs@primary@lc03@dataset: [ 0.  0.]\n",
      "ld_coeffs@secondary@lc03@dataset: [ 0.25  0.25]\n"
     ]
    }
   ],
   "source": [
    "print b['ld_coeffs@lc03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we didn't explicitly override the defaults for '\\_default', so they used the phoebe-wide defaults.  If you wanted to set a value for the ld_coeffs of any star added in the future, you would have to provide a value for '\\_default' in the dictionary as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syntax may seem a bit bulky - but alternatively you can add the dataset without providing values and then change the values individually using dictionary access or set_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a Dataset from a File\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually from Arrays\n",
    "\n",
    "For now, the only way to load data from a file is to do the parsing externally and pass the arrays on (as in the previous section).\n",
    "\n",
    "Here we'll load times, fluxes, and errors of a light curve from an external file and then pass them on to a newly created dataset.  Since this is a light curve, it will automatically know that you want the summed light from all copmonents in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | methods: LC, LC_dep>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times, fluxes, errors = np.loadtxt('test.lc.in', unpack=True)\n",
    "b.add_dataset(phoebe2.dataset.lc, time=times, flux=fluxes, sigma=errors, dataset='lc04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Parsing File\n",
    "\n",
    "COMING SOON - maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling and Disabling Datasets\n",
    "---------------------------------------\n",
    "\n",
    "COMING SOON - probably just point to the next tutorial (compute)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Phases\n",
    "-------------------------------\n",
    "\n",
    "Datasets will no longer accept phases.  It is the user's responsibility to convert\n",
    "phased data into times given an ephemeris.  But it's still useful to be able to\n",
    "convert times to phases (and vice versa) and be able to plot in phase.\n",
    "\n",
    "The following functions handle those conversions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dpdt': 0.0, 'phshift': 0.0, 'period': 3.0, 't0': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print b.get_ephemeris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print b.to_phase(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.75\n"
     ]
    }
   ],
   "source": [
    "print b.to_time(-0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these by default use the period in the top-level of the current hierarchy,\n",
    "but accept a component keyword argument if you'd like the ephemeris of an\n",
    "inner-orbit or the rotational ephemeris of a star in the system.\n",
    "\n",
    "We'll see how plotting works later, but if you manually wanted to plot the dataset\n",
    "with phases, all you'd need to do is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.1754386   0.35087719  0.52631579  0.70175439  0.87719298\n",
      "  0.05263158  0.22807018  0.40350877  0.57894737  0.75438596  0.92982456\n",
      "  0.10526316  0.28070175  0.45614035  0.63157895  0.80701754  0.98245614\n",
      "  0.15789474  0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print b.to_phase(b['time@primary@orb01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.1754386   0.35087719  0.52631579  0.70175439  0.87719298\n",
      "  0.05263158  0.22807018  0.40350877  0.57894737  0.75438596  0.92982456\n",
      "  0.10526316  0.28070175  0.45614035  0.63157895  0.80701754  0.98245614\n",
      "  0.15789474  0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print b.to_phase('time@primary@orb01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TODO: show how to load data that was phased (not yet supported)\n",
    "* TODO: point to how to plot phased data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Datasets\n",
    "----------------------\n",
    "\n",
    "Removing a dataset will remove matching parameters in either the dataset, model, or constraint contexts.  This action is permanent and not undo-able via [Undo/Redo](undo_redo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rv04',\n",
       " 'rv01',\n",
       " 'rv02',\n",
       " 'rv03',\n",
       " 'orb02',\n",
       " 'orb01',\n",
       " 'lc03',\n",
       " 'lc02',\n",
       " 'lc01',\n",
       " 'lc04']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to remove a dataset is by its dataset tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.remove_dataset('lc01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rv04', 'rv01', 'rv02', 'rv03', 'orb02', 'orb01', 'lc03', 'lc02', 'lc04']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remove_dataset also takes any other tag(s) that could be sent to filter.\n",
    "\n",
    "**WARNING**: since remove_dataset removes from contexts other than just 'dataset', this will remove **all** Parameters that match the filter provided.  There are some precautions in place that will raise Errors if you leave the filter blank or try to pass a qualifier, but it isn't a bad idea to test the filter first to ensure you aren't removing Parameters that you don't want removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.remove_dataset(method='RV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orb02', 'lc02', 'orb01', 'lc03', 'lc04']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dataset Types\n",
    "------------------------\n",
    "\n",
    "For a full explanation of all related options and Parameter see the respective dataset tutorials:\n",
    "\n",
    "* [ORB dataset](ORB)\n",
    "* [MESH dataset](MESH)\n",
    "* [LC dataset](LC)\n",
    "* [RV dataset](RV)\n",
    "* [ETV dataset](ETV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
